# -*- coding: utf-8 -*-
"""Untitled26.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1VU7qyXYxkvmAudh89XgZnjl5Bk41wC3i
"""

import pandas as pd
import numpy as np

df=pd.read_csv("/content/Train.csv")

df.head()

df.info()

df.describe()

df.isnull().sum()

for i in df.columns:
  
    print(i,len(df[i].unique()))

import matplotlib.pyplot as plt
for i in df.columns:
  print(i)
  df[i].hist()
  plt.show()

df.info()

df=df.drop("Item_Identifier",axis=1)

from numpy import nan
from pandas import read_csv
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score

df.fillna(df.mean(), inplace=True)

df.fillna(df.mode(), inplace=True)

df['Outlet_Size'].fillna(df['Outlet_Size'].value_counts().index[0],inplace=True)

for i in df.columns:
  if df[i].dtypes=="object":
    df[i]= label_encoder.fit_transform(df[i])

from sklearn import preprocessing
# label_encoder object knows how to understand word labels. 
label_encoder = preprocessing.LabelEncoder()

from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import train_test_split
X=df.drop("Item_Outlet_Sales",axis=1)
y=df["Item_Outlet_Sales"]

X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.25,random_state=14)

rfc=RandomForestRegressor()
rfc.fit(X_train,y_train)

rfc.score(X_test,y_test)

pred=modelt.predict(X_test)

from sklearn.metrics import mean_squared_error
mean_squared_error(y_test,pred)

rfc.feature_importances_

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler().fit(X)
X_scaled = scaler.transform(X)

import xgboost as xgb
from xgboost import XGBRegressor
modelt = XGBRegressor()

modelt.fit(X_train,y_train)

modelt.score(X_test,y_test)

from sklearn.ensemble import AdaBoostRegressor
from lightgbm import LGBMRegressor

model1=AdaBoostRegressor()

model1.fit(X_train,y_train)
model1.score(X_test,y_test)

model2=LGBMRegressor()
model2.fit(X_train,y_train)
model2.score(X_test,y_test)

xgbooster = XGBRegressor(random_state=42, booster='gbtree', learning_rate=0.1, max_depth=8, n_estimators=600)

xgbooster.fit(X_train,y_train)

xgbooster.score(X_test,y_test)

from keras.models import Sequential
from keras.layers import Dense
model = Sequential()
model.add(Dense(26, input_dim=30, kernel_initializer='normal', activation='relu'))
model.add(Dense(13,  activation='relu'))
model.add(Dense(1, kernel_initializer='normal'))
  
model.compile(loss='mean_squared_error', optimizer='adam',metrics=["mae", "acc"],)

model.fit(X_scaled,y,epochs=10, batch_size=5)

predf=model.predict(X_test)

from sklearn.datasets import make_regression
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import RepeatedKFold
from sklearn.linear_model import LinearRegression
from sklearn.neighbors import KNeighborsRegressor
from sklearn.tree import DecisionTreeRegressor
from sklearn.svm import SVR
from sklearn.ensemble import StackingRegressor
from matplotlib import pyplot
level0 = list()
level0.append(('knn', XGBRegressor(random_state=42, booster='gbtree', learning_rate=0.1, max_depth=8, n_estimators=600)))
level0.append(('cart', LGBMRegressor()))
level0.append(('svm', RandomForestRegressor(max_depth=25,
 max_features= 'sqrt',
    min_samples_leaf= 1,
          min_samples_split= 2,
                    n_estimators= 1000)))
level0.append(('cart1',SVR()))
level0.append(('cart2',LinearRegression()))
level0.append(('cart3',KNeighborsRegressor()))
level1 = LinearRegression()

model = StackingRegressor(estimators=level0, final_estimator=level1, cv=5)

model.fit(X_train,y_train)

model.score(X_test,y_test)

cat_var = df.select_dtypes(include =[np.object])
cat_var.shape

num_var = df.select_dtypes(include=[np.float64])
num_var.shape

for var in cat_var:
      df[var].fillna(method='ffill',inplace=True)

for var in num_var:
      mean = np.around(np.mean(df[var]))
      df[var].fillna(mean,inplace = True)

visibility_avg = df.pivot_table(values='Item_Visibility', index='Item_Identifier')

#Impute 0 values with mean visibility of that product:
missing_values = (df['Item_Visibility'] == 0)

df.loc[missing_values,'Item_Visibility'] = df.loc[missing_values,'Item_Identifier'].apply(lambda x: visibility_avg.at[x, 'Item_Visibility'])

df['Item_Type_Combined'] = df['Item_Identifier'].apply(lambda x:x[0:2])
df['Item_Type_Combined'] = df['Item_Type_Combined'].map({'FD':'food','NC':'Non_consum','DR':'Drink'})
df['Item_Type_Combined'].value_counts()

df['Item_Fat_Content'] = df['Item_Fat_Content'].replace({'LF':'Low Fat','reg':'Regular','low fat':'Low Fat'})

df['Outlet_Year'] = 2019 - df['Outlet_Establishment_Year']
df['Outlet_Year'].describe()

from sklearn.preprocessing import LabelEncoder

encode = LabelEncoder()

df['Outlet'] = encode.fit_transform(df['Outlet_Identifier'])

var_mod = ['Item_Fat_Content','Outlet_Location_Type','Outlet_Size','Item_Type_Combined','Outlet_Type','Outlet']
for i in var_mod:
    df[i] = encode.fit_transform(df[i])

df = pd.get_dummies(df,columns =)

df.head()

df=df.drop(["Item_Identifier","Item_Type","Outlet_Identifier"],axis=1)